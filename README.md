# A comparative study of fairness methods for clinical predictions using the MIMIC-IV database

Fairness-aware interpretable modeling (FAIM) [1] is an in-processing fairness method that avoids extreme performance degradation while improving fairness and maintaining interpretability.

This repository contains the Jupyter notebooks with the coding portion of the thesis work conducted to fulfill the requirements for the master's degree in data science from the University of Barcelona supervised by Dr. Laura Igual Muñoz. 

The study consists of the reproduction of the results reached in the original FAIM study with the clinical prediction task of hospital admission after emergency department (ED) stay utilizing the code provided in [2], followed by stress-testing the FAIM workflow with the unique task of invasive mechanical ventilation (IMV) prediction as inspired by [3].

## Repository Contents:
### Notebooks:


### Reports:



## References
[1] M. Liu et al., "FAIM: Fairness-aware interpretable modeling for trustworthy machine learning in healthcare," *Patterns*, vol. 5, Oct. 2024. https://doi.org/10.1016/j.patter.2024.241059

[2] NliuLab, “FAIM: Fairness-aware interpretable modeling.” GitHub repository, 2025. Available: https://github.com/nliulab/FAIM/tree/main.

[3] F. M. Abdelmalek et al., “Association between patient race and ethnicity and use of invasive ventilation in the United States,” Ann. Am. Thorac. Soc., vol. 21, pp. 287–295, Feb. 2024.
